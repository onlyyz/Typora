#### 一、简介

<font color=#4db8ff>Link：</font>https://frankorz.com/2021/04/17/compute-shader/#fn1

1.1 基础知识

Dispatch(5,3,2)、numthreads 属性中指定的值 numthreads(10,8,3)

![线程组 3D 网格](http://img.frankorz.com/dx-grid-of-thread-group.png)

```c++
[numthreads(8,8,1)]        // 线程组中的线程数
Dispatch(ComputeShader, mainKernel, 4, 3, 2)
```

dispatch最后三个参数，表示要使用多少个Thread Group

（4，3，2）表示4x3x2 = 24个线程组。类似2张横向长度为4，竖向长度为3的表格。表格中的每一格都是一个numthread(8,2,4)的thread group。

| 参数                | 值类型 | 含义                                                         | 计算公式                                                     |
| ------------------- | ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| SV_GroupID          | int3   | 当前线程所在的线程组的ID，取值范围为(0,0,0)到(gX-1,gY-1,gZ-1)。 | 无                                                           |
| SV_GroupThreadID    | int3   | 当前线程在所在线程组内的ID，取值范围为(0,0,0)到(tX-1,tY-1,tZ-1)。 | 无                                                           |
| SV_DispatchThreadID | int3   | 当前线程在所有线程组中的所有线程里的ID，取值范围为(0,0,0)到(gX*tX-1, gY*tY-1, gZ*tZ-1)。 | 假设该线程的SV_GroupID=(a, b, c)，SV_GroupThreadID=(i, j, k) 那么SV_DispatchThreadID=(a*tX+i, b*tY+j, c*tZ+k) |
| SV_GroupIndex       | int    | 当前线程在所在线程组内的下标，取值范围为0到tX*tY*tZ-1。      | 假设该线程的SV_GroupThreadID=(i, j, k) 那么SV_GroupIndex=k*tX*tY+j*tX+i |





**SP**：最基本的处理单元，streaming processor，也称为 CUDA core。最后具体的指令和任务都是在 SP 上处理的。GPU 进行并行计算，也就是很多个 SP 同时做处理。我们所说的几百核心的 GPU 值指的都是 SP 的数量；

**SM**：多个 SP 加上其他的一些资源组成一个 streaming multiprocessor。也叫 GPU 大核

其他资源如：warp scheduler，register，shared memory 等。SM 可以看做 GPU 的心脏（对比 CPU 核心），register 和 shared memory 是 SM 的稀缺资源。CUDA 将这些资源分配给所有驻留在 SM 中的 threads。

因此，这些有限的资源就使每个 SM 中 active warps 有非常严格的限制，也就限制了并行能力。

这些核心被组织在流式多处理器（<font color=#4db8ff>streaming multiprocessor, SM</font>）中，一个线程组运行于一个多处理器（SM）之上。每一个核心同一时间可以运行一个线程。

流式多处理器（streaming multiprocessor, SM）是 Nvidia 的说法，AMD 对应的单元则是 Compute Unit。

，对于拥有 16 个 SM 的 GPU 来说，我们至少应将任务分解为 16 个线程组，来让每个多处理器都充分地运转起来。但是，要获得更佳的性能，我们还应当令每个多处理器至少拥有两个线程组，使它能够切换到不同的线程组进行处理，以连续不停地工作（线程组在运行的过程中可能会发生停顿，例如，着色器在继续执行下一个指令之前会等待纹理的处理结果，此时即可切换至另一个线程组）。

##### 1.2 Warp

SM 会将它从 Gigathread 引擎（NVIDIA 技术，专门管理整个流水线）那收到的大线程块，拆分成许多更小的堆，每个堆包含<font color=#4db8ff> 32 </font>个线程

这样的堆也被称为：**warp** (AMD 则称为 **wavefront**)。

多处理器会以 SIMD32 的方式（即 32 个线程同时执行相同的指令序列）来处理 warp，每个 CUDA 核心都可处理一个线程。

如果我们定义 `numthreads(8, 2, 4)`，那么每个线程组就有8×2×4=64个线程，这一整个线程组会被分成两个 warp，调度到单个<font color=#4db8ff> SIMD </font>单元计算。

##### 1.3 线程

```cpp
[numthreads(8,8,1)]
```

定义**一个线程组（Thread Group）中可以被执行的线程（Thread）总数量。**